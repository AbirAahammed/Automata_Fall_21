{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automate CFL string creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transition:\n",
    "    def __init__(self, variable, to) -> None:\n",
    "        self.variable = variable\n",
    "        self.to = to\n",
    "    def str(self):\n",
    "        return '{} --> {}'.format(self.variable, ''.join(self.to))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFL:\n",
    "    def __init__(self, variables, terminals, transitions) -> None:\n",
    "        self.variables = variables\n",
    "        self.terminals = terminals\n",
    "        self.transitions = transitions\n",
    "    def generate_str(self):\n",
    "        s_v = self.transitions[0].variable\n",
    "        n_str = [i for i in self.transitions]\n",
    "        print(s_v)\n",
    "        print(n_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfl = CFL(\n",
    "    ['S'], \n",
    "    ['0', '1', ''], \n",
    "    [\n",
    "        Transition('S', ['0', 'S', '1']),\n",
    "        Transition('S', ['S', 'S']),\n",
    "        Transition('S', [''])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S\n",
      "['S --> 0S1', 'S --> SS', 'S --> ']\n"
     ]
    }
   ],
   "source": [
    "cfl.generate_str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'S': '0S1'}, {'S': 'SS'}, {'S': ''}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thisdict = {\n",
    "  \"S\": \"0S1\",\n",
    "  \"S\": \"SS\",\n",
    "  \"S\": \"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0S0S1S0S1S1'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"001011\"\n",
    "s = 'S'.join([i for i in s])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0SSSSS1'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = s.replace('0S1', 'S')\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0SSSSS1'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfl = {\n",
    "  \"S\": [\"0S1\",\"SS\",\"\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0S1', 'SS', '']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfl[\"S\"]\n",
    "first = cfl[\"S\"]\n",
    "first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0S1'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World! -> ['Hello', ',', 'World', '!']\n"
     ]
    }
   ],
   "source": [
    "from pyparsing import Word, alphas\n",
    "greet = Word(alphas) + \",\" + Word(alphas) + \"!\"\n",
    "hello = \"Hello, World!\"\n",
    "print(hello, \"->\", greet.parseString(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chart[0]\n",
      "S0 gamma -> \\bullet S  [0, 0] [] dummy start state\n",
      "S1 S -> \\bullet NP VP  [0, 0] [] predictor\n",
      "S2 S -> \\bullet Aux NP VP  [0, 0] [] predictor\n",
      "S3 S -> \\bullet VP  [0, 0] [] predictor\n",
      "S4 NP -> \\bullet Det Nominal  [0, 0] [] predictor\n",
      "S5 NP -> \\bullet Proper-Noun  [0, 0] [] predictor\n",
      "S6 VP -> \\bullet Verb  [0, 0] [] predictor\n",
      "S7 VP -> \\bullet Verb NP  [0, 0] [] predictor\n",
      "\n",
      "Chart[1]\n",
      "S8 Verb -> book \\bullet [0, 1] [] scanner\n",
      "S9 VP -> Verb \\bullet [0, 1] [8] completer\n",
      "S10 VP -> Verb \\bullet NP  [0, 1] [8] completer\n",
      "S11 S -> VP \\bullet [0, 1] [9] completer\n",
      "S12 NP -> \\bullet Det Nominal  [1, 1] [] predictor\n",
      "S13 NP -> \\bullet Proper-Noun  [1, 1] [] predictor\n",
      "\n",
      "Chart[2]\n",
      "S14 Det -> that \\bullet [1, 2] [] scanner\n",
      "S15 NP -> Det \\bullet Nominal  [1, 2] [14] completer\n",
      "S16 Nominal -> \\bullet Noun  [2, 2] [] predictor\n",
      "S17 Nominal -> \\bullet Noun Nominal  [2, 2] [] predictor\n",
      "\n",
      "Chart[3]\n",
      "S18 Noun -> flight \\bullet [2, 3] [] scanner\n",
      "S19 Nominal -> Noun \\bullet [2, 3] [18] completer\n",
      "S20 Nominal -> Noun \\bullet Nominal  [2, 3] [18] completer\n",
      "S21 NP -> Det Nominal \\bullet [1, 3] [14, 19] completer\n",
      "S22 Nominal -> \\bullet Noun  [3, 3] [] predictor\n",
      "S23 Nominal -> \\bullet Noun Nominal  [3, 3] [] predictor\n",
      "S24 VP -> Verb NP \\bullet [0, 3] [8, 21] completer\n",
      "S25 Nominal -> Noun Nominal \\bullet [2, 3] [18, 22] completer\n",
      "S26 S -> VP \\bullet [0, 3] [24] completer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class State(object):\n",
    "    def __init__(self, label, rules, dot_idx, start_idx, end_idx, idx, made_from, producer):\n",
    "        self.label = label\n",
    "        self.rules = rules\n",
    "        self.dot_idx = dot_idx\n",
    "        self.start_idx = start_idx\n",
    "        self.end_idx = end_idx\n",
    "        self.idx = idx\n",
    "        self.made_from = made_from\n",
    "        self.producer = producer\n",
    "\n",
    "    def next(self):\n",
    "        \"\"\"Returns the tag after the dot\"\"\"\n",
    "        return self.rules[self.dot_idx]\n",
    "\n",
    "    def complete(self):\n",
    "        return len(self.rules) == self.dot_idx\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (self.label == other.label and\n",
    "                self.rules == other.rules and\n",
    "                self.dot_idx == other.dot_idx and\n",
    "                self.start_idx == other.start_idx and\n",
    "                self.end_idx == other.end_idx)\n",
    "\n",
    "    def __str__(self):\n",
    "        rule_string = ''\n",
    "        for i, rule in enumerate(self.rules):\n",
    "            if i == self.dot_idx:\n",
    "                rule_string += '\\\\bullet '\n",
    "            rule_string += rule + ' '\n",
    "        if self.dot_idx == len(self.rules):\n",
    "            rule_string += '\\\\bullet'\n",
    "        return 'S%d %s -> %s [%d, %d] %s %s' % (self.idx, self.label, rule_string, self.start_idx, \n",
    "                                                self.end_idx, self.made_from, self.producer)\n",
    "\n",
    "class Earley:\n",
    "    def __init__(self, words, grammar, terminals):\n",
    "        self.chart = [[] for _ in range(len(words) + 1)]\n",
    "        self.current_id = 0\n",
    "        self.words = words\n",
    "        self.grammar = grammar\n",
    "        self.terminals = terminals\n",
    "\n",
    "    def get_new_id(self):\n",
    "        self.current_id += 1\n",
    "        return self.current_id - 1\n",
    "\n",
    "    def is_terminal(self, tag):\n",
    "        return tag in self.terminals\n",
    "\n",
    "    def is_complete(self, state):\n",
    "        return len(state.rules) == state.dot_idx\n",
    "\n",
    "    def enqueue(self, state, chart_entry):\n",
    "        if state not in self.chart[chart_entry]:\n",
    "            self.chart[chart_entry].append(state)\n",
    "        else:\n",
    "            self.current_id -= 1\n",
    "\n",
    "    def predictor(self, state):\n",
    "        for production in self.grammar[state.next()]:\n",
    "            self.enqueue(State(state.next(), production, 0, state.end_idx, state.end_idx, self.get_new_id(), [], 'predictor'), state.end_idx)\n",
    "\n",
    "    def scanner(self, state):\n",
    "        if self.words[state.end_idx] in self.grammar[state.next()]:\n",
    "            self.enqueue(State(state.next(), [self.words[state.end_idx]], 1, state.end_idx, state.end_idx + 1, self.get_new_id(), [], 'scanner'), state.end_idx + 1)\n",
    "\n",
    "    def completer(self, state):\n",
    "        for s in self.chart[state.start_idx]:\n",
    "            if not s.complete() and s.next() == state.label and s.end_idx == state.start_idx and s.label != 'gamma':\n",
    "                self.enqueue(State(s.label, s.rules, s.dot_idx + 1, s.start_idx, state.end_idx, self.get_new_id(), s.made_from + [state.idx], 'completer'), state.end_idx)\n",
    "\n",
    "    def parse(self):\n",
    "        self.enqueue(State('gamma', ['S'], 0, 0, 0, self.get_new_id(), [], 'dummy start state'), 0)\n",
    "        \n",
    "        for i in range(len(self.words) + 1):\n",
    "            for state in self.chart[i]:\n",
    "                if not state.complete() and not self.is_terminal(state.next()):\n",
    "                    self.predictor(state)\n",
    "                elif i != len(self.words) and not state.complete() and self.is_terminal(state.next()):\n",
    "                    self.scanner(state)\n",
    "                else:\n",
    "                    self.completer(state)\n",
    "\n",
    "    def __str__(self):\n",
    "        res = ''\n",
    "        \n",
    "        for i, chart in enumerate(self.chart):\n",
    "            res += '\\nChart[%d]\\n' % i\n",
    "            for state in chart:\n",
    "                res += str(state) + '\\n'\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "def test():\n",
    "    grammar = {\n",
    "        'S':           [['NP', 'VP'], ['Aux', 'NP', 'VP'], ['VP']],\n",
    "        'NP':          [['Det', 'Nominal'], ['Proper-Noun']],\n",
    "        'Nominal':     [['Noun'], ['Noun', 'Nominal']],\n",
    "        'VP':          [['Verb'], ['Verb', 'NP']],\n",
    "        'Det':         ['that', 'this', 'a'],\n",
    "        'Noun':        ['book', 'flight', 'meal', 'money'],\n",
    "        'Verb':        ['book', 'include', 'prever'],\n",
    "        'Aux':         ['does'],\n",
    "        'Prep':        ['from', 'to', 'on'],\n",
    "        'Proper-Noun': ['Houston', 'TWA']\n",
    "    }\n",
    "    terminals = ['Det', 'Noun', 'Verb', 'Aux', 'Prep', 'Proper-Noun']\n",
    "\n",
    "    earley = Earley(['book', 'that', 'flight'], grammar, terminals)\n",
    "    earley.parse()\n",
    "    print(earley)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "67176aa62ce702ae4822ae5a2222842b74bf2fe1fdc4a19d69f0ad18bd063919"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 32-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
